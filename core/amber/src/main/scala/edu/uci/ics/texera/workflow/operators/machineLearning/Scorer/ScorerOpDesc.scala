package edu.uci.ics.texera.workflow.operators.machineLearning.Scorer

import com.fasterxml.jackson.annotation.{JsonProperty, JsonPropertyDescription}
import com.kjetland.jackson.jsonSchema.annotations.{JsonSchemaInject, JsonSchemaString, JsonSchemaTitle}
import edu.uci.ics.amber.engine.common.workflow.{InputPort, OutputPort, PortIdentity}
import edu.uci.ics.texera.workflow.common.metadata.annotations.{AutofillAttributeName, AutofillAttributeNameOnPort1, HideAnnotation}
import edu.uci.ics.texera.workflow.common.metadata.{OperatorGroupConstants, OperatorInfo}
import edu.uci.ics.texera.workflow.common.operators.PythonOperatorDescriptor
import edu.uci.ics.texera.workflow.common.tuple.schema.{Attribute, AttributeType, Schema}

class ScorerOpDesc extends PythonOperatorDescriptor {
  @JsonProperty(required = true)
  @JsonSchemaTitle("Actual Value")
  @JsonPropertyDescription("Specify the label column")
  @AutofillAttributeName
  var actualValueColumn: String = ""

  @JsonProperty(required = true)
  @JsonSchemaTitle("Predicted Value")
  @JsonPropertyDescription("Specify the attribute generated by the model")
  @AutofillAttributeNameOnPort1
  var predictValue: String = ""

  @JsonProperty(defaultValue = "false")
  @JsonSchemaTitle("Using probability?")
  @JsonSchemaInject(json = """{"toggleHidden" : ["probabilityValue"]}""")
  var is_prob: Boolean = _

  @JsonProperty()
  @JsonSchemaTitle("Probability Column")
  @JsonPropertyDescription("Specify the name of the predicted probability")
  @JsonSchemaInject(
    strings = Array(
      new JsonSchemaString(path = HideAnnotation.hideTarget, value = "is_prob"),
      new JsonSchemaString(path = HideAnnotation.hideType, value = HideAnnotation.Type.equals),
      new JsonSchemaString(path = HideAnnotation.hideExpectedValue, value = "false")
    )
  )
  @AutofillAttributeNameOnPort1
  var probabilityValue: String = ""

  @JsonProperty(required = true)
  @JsonSchemaTitle("Scorer Functions")
  @JsonPropertyDescription("Select multiple score functions")
  var scorers: List[ScorerFunction] = List()
  override def operatorInfo: OperatorInfo =
    OperatorInfo(
      "Scorer",
      "Scorer for machine learning classifier",
      OperatorGroupConstants.ML_GROUP,
      inputPorts = List(
        InputPort(
          PortIdentity(0),
          displayName = "GroundTruth",
        ),
        InputPort(
          PortIdentity(1),
          displayName = "PredictValue",
          dependencies = List(PortIdentity(0)))),
      outputPorts = List(OutputPort())
    )

  override def generatePythonCode(): String = {
    val finalcode =
      s"""
         |from pytexera import *
         |import pandas as pd
         |import numpy as np
         |from sklearn.metrics import accuracy_score
         |from sklearn.metrics import precision_score
         |from sklearn.metrics import confusion_matrix
         |from sklearn.metrics import recall_score
         |from sklearn.metrics import f1_score
         |import json
         |
         |
         |def label_confusion_matrix(y_true, y_pred, label):
         |    labelCM = [None] * len(label)
         |    cm = confusion_matrix(y_true, y_pred, labels = label)
         |
         |    for i in range(len(cm)):
         |        tp = cm[i, i]
         |        fp = np.sum(cm[:, i]) - tp
         |        fn = np.sum(cm[i, :]) - tp
         |        tn = np.sum(cm) - tp - fp - fn
         |        f1 = f1_score(y_true, y_pred, average = None, labels = [label[i]])
         |        precision = precision_score(y_true, y_pred, average = None, labels = [label[i]])
         |        recall = recall_score(y_true, y_pred, average = None, labels = [label[i]])
         |
         |        labelCM[i] = [label[i], tp, fp, fn, tn, f1[0], precision[0], recall[0]]
         |
         |    return labelCM
         |
         |
         |class ProcessTableOperator(UDFTableOperator):
         |
         |    @overrides
         |    def process_table(self, table: Table, port: int) -> Iterator[Optional[TableLike]]:
         |        global groundTruthTable
         |        global predictValueTable
         |
         |        if port == 0:
         |            groundTruthTable = table
         |
         |        if port == 1:
         |            predictValueTable = table
         |            result = dict()
         |
         |            if '$probabilityValue' != '':
         |              if predictValueTable['$probabilityValue'][0].dtype not in [float, 'float64', 'float32']:
         |                print("Probability Column not correct")
         |              else:
         |                result['$probabilityValue'] = predictValueTable['$probabilityValue'].tolist()
         |
         |
         |            y_true = groundTruthTable['$actualValueColumn']
         |            y_pred = predictValueTable['$predictValue'][0]
         |            labels = list(set(y_true))
         |
         |            scorerList = [${getSelectedScorers()}]
         |
         |            for scorer in scorerList:
         |              prediction = None
         |              if scorer == 'Accuracy':
         |                prediction = accuracy_score(y_true, y_pred)
         |                result['Accuracy'] = prediction
         |              elif scorer == 'Precision Score':
         |                prediction = precision_score(y_true, y_pred, average = 'macro')
         |                result['Precision Score'] = prediction
         |              elif scorer == 'Recall Score':
         |                prediction = recall_score(y_true, y_pred, average = 'macro')
         |                result['Recall Score'] = prediction
         |              elif scorer == 'F1 Score':
         |                prediction = f1_score(y_true, y_pred, average = 'macro')
         |                result['F1 Score'] = prediction
         |              elif scorer == 'Confusion Matrix':
         |                prediction = confusion_matrix(y_true, y_pred, labels = labels)
         |                prediction_json = json.dumps(prediction.tolist(), indent = 4)
         |                result['Confusion Matrix'] = prediction_json

         |
         |            print(label_confusion_matrix(y_true, y_pred, labels))
         |            result['Label_CM'] = str(label_confusion_matrix(y_true, y_pred, labels)) # 2D List 好像不能直接傳？
         |            result['model'] = predictValueTable['model'].tolist()
         |            result['para'] = predictValueTable['para'].tolist()
         |
         |            df = pd.DataFrame(result, index=[0])
         |            df['Iteration'] = table['Iteration']
         |            yield df
         |
         |""".stripMargin
    finalcode
  }
  override def getOutputSchema(schemas: Array[Schema]): Schema = {
    val outputSchemaBuilder = Schema.newBuilder
    outputSchemaBuilder.add(new Attribute("Iteration", AttributeType.INTEGER))
    outputSchemaBuilder.add(new Attribute("Label_CM", AttributeType.STRING))
    scorers.map(scorer => getEachScorerName(scorer)).foreach(scorer =>
    {
      if (scorer == "Confusion Matrix") {
        outputSchemaBuilder.add(new Attribute(scorer, AttributeType.STRING))
      } else {
        outputSchemaBuilder.add(new Attribute(scorer, AttributeType.DOUBLE))
      }
    }
    )
    outputSchemaBuilder.add(new Attribute("para", AttributeType.STRING))
    outputSchemaBuilder.add(new Attribute("model", AttributeType.BINARY))
    if(is_prob) {
      outputSchemaBuilder.add(new Attribute(probabilityValue, AttributeType.BINARY))
    }

    outputSchemaBuilder.build
  }


  private def getEachScorerName(scorer: ScorerFunction): String = {
    // Directly return the name of the scorer using the getName() method
    scorer.getName()
  }
  private def getSelectedScorers(): String = {
    // Return a string of scorers using the getEachScorerName() method
    scorers.map(scorer => getEachScorerName(scorer)).mkString("'", "','", "'")
  }


}